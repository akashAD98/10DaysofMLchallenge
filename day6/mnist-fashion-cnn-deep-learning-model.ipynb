{"cells":[{"metadata":{},"cell_type":"markdown","source":"# labels"},{"metadata":{},"cell_type":"markdown","source":"Each training and test example is assigned to one of the following labels:\n\n0 T-shirt/top\n1 Trouser\n2 Pullover\n3 Dress\n4 Coat\n5 Sandal\n6 Shirt\n7 Sneaker\n8 Bag\n9 Ankle boot\nTL;DR\nEach row is a separate image\nColumn 1 is the class label.\nRemaining columns are pixel numbers (784 total).\nEach value is the darkness of the pixel (1 to 255)\nAcknowledgements\nOriginal dataset was downloaded from https://github.com/zalandoresearch/fashion-mnist\n\nDataset was converted to CSV with this script: https://pjreddie.com/projects/mnist-in-csv/************"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import TensorBoard\nnum_classes = 10\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create dataframes for train and test datasets"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/fashionmnist/fashion-mnist_train.csv',sep=',')\ntest_df= pd.read_csv('../input/fashionmnist/fashion-mnist_test.csv', sep = ',')\nprint(\"Train size:{}\\nTest size:{}\".format(train_df.shape, test_df.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us explore the train and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now it is observed that the first column is the label data and because it has 10 classes so it is going to have from 0 to 9.The remaining columns are the actual pixel data.Here as you can see there are about 784 columns that contain pixel data. Here each row is a different image representation in the form pixel data.\n\nNow let us split the train data into x and y arrays where x represents the image data and y represents the labels.\n\nTo do that we need to convert the dataframes into numpy arrays of float32 type which is the acceptable form for tensorflow and keras."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = np.array(train_df, dtype = 'float32')\ntest_data = np.array(test_df, dtype='float32')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = train_data[:,1:]/255\n\ny_train = train_data[:,0]\n\nx_test= test_data[:,1:]/255\n\ny_test=test_data[:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_validate,y_train,y_validate = train_test_split(x_train,y_train,test_size = 0.2,random_state = 12345)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = x_train[22,:].reshape((28,28))\nplt.imshow(image)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create the Convolutional Neural Networks (CNN)\n#### Define the model\n\n#### Compile the model\n\n#### Fit the model\n\nFirst of all let us define the shape of the image before we define the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_rows = 28\n\nimage_cols = 28\n\nbatch_size = 512\n\nimage_shape = (image_rows,image_cols,1) # Defined the shape of the image as 3d with rows and columns and 1 for the 3d visualisation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = x_train.reshape(x_train.shape[0],*image_shape)\nx_test = x_test.reshape(x_test.shape[0],*image_shape)\nx_validate = x_validate.reshape(x_validate.shape[0],*image_shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"># define model"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_model = Sequential([\n    Conv2D(filters=32,kernel_size=3,activation='relu',input_shape = image_shape),\n    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n    Dropout(0.5),\n    Flatten(), # flatten out the layers\n    Dense(32,activation='relu'),\n    Dense(10,activation = 'softmax')\n    \n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"compile model"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_model.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001),metrics =['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = cnn_model.fit(\n    x_train,\n    y_train,\n    batch_size=batch_size,\n    epochs=17,\n    verbose=1,\n    validation_data=(x_validate,y_validate),\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = cnn_model.evaluate(x_test,y_test,verbose=0)\nprint('Test Loss : {:.4f}'.format(score[0]))\nprint('Test Accuracy : {:.4f}'.format(score[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results\nLet's plot training and validation accuracy as well as loss.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Complexity Graph:  Training vs. Validation Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validate'], loc='upper right')\n\nplt.figure(2)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy Graph:  Training vs. Validation accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validate'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# classification_report"},{"metadata":{"trusted":true},"cell_type":"code","source":"\npredicted_classes = cnn_model.predict_classes(x_test)\n\n#get the indices to be plotted\n\ny_true = test_df.iloc[:, 0]\n\ncorrect = np.nonzero(predicted_classes==y_true)[0]\n\nincorrect = np.nonzero(predicted_classes!=y_true)[0]\n\nfrom sklearn.metrics import classification_report\n\ntarget_names = [\"Class {}\".format(i) for i in range(num_classes)]\n\nprint(classification_report(y_true, predicted_classes, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"# Here is a subset of correctly predicted classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\nnum_rows = 5\nnum_cols = 10\nsample_size = num_rows * num_cols\nindices = np.arange(sample_size)\nx_pred = x_test[indices,:,:]\npredictions = cnn_model.predict(x_pred)\nx_pred = np.squeeze(x_test[indices,:,:])\ny_pred = np.argmax(predictions,axis=1)\n\nnum_images = num_rows*num_cols\nplt.figure(figsize=(num_cols*2, num_rows*2))\nplt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.6)\nfor i in range(num_images):\n  plt.subplot(num_rows, num_cols, i+1)\n  plt.imshow(x_pred[i])\n  plt.title(classes[y_pred[i]])\n  # plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  # plot_value_array(i, predictions, test_labels)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}